---
title: "Privacy Malware Classifiers based on Memory Dumping Analysis - Privacy Malware Families Classification"
author: "David Cevallos-Salas, Felipe Grijalva, José Estrada-Jiménez, Diego Benítez and Roberto Andrade"
output: html_notebook
---

```{r, warning=FALSE}
# Global configuration
knitr::opts_chunk$set(echo = TRUE)

# Libraries
library(ggplot2)
library(viridis)
library(kableExtra)
library(dplyr)
library(sur)
library(qqplotr)
library(DescTools)
library(phia)
library(emmeans)
library(multcompView)
library(multcomp, quietly = TRUE)
library(ggradar)

# Viridis palette
palette1 <- viridis(6, alpha= 1, begin = 0, end = 1, direction = 1, option="viridis")
palette2 <- viridis(6, alpha= 1, begin = 0, end = 1, direction = 1, option="viridis")
```


```{r, warning=FALSE}
# Decision Tree
dt_nsm = c(0.593,0.592,0.590,0.587,0.588,0.587,0.590,0.593,0.591, 0.590)
dt_sm = c(0.591,0.592,0.587,0.593,0.588,0.592,0.589,0.588,0.594,0.592)
mean(dt_nsm)
sd(dt_nsm)
mean(dt_sm)
sd(dt_sm)
fligner.test(dt_nsm,dt_sm)
wilcox.test(dt_nsm,dt_sm,alternative="less")
```

```{r, warning=FALSE}
# Random Forest
rf_nsm = c(0.621,0.623,0.613,0.620,0.616,0.611,0.617,0.619,0.622,0.618)
rf_sm = c(0.620,0.622,0.615,0.619,0.615,0.615,0.617,0.620,0.623,0.621)
mean(rf_nsm)
sd(rf_nsm)
mean(rf_sm)
sd(rf_sm)
fligner.test(rf_nsm,rf_sm)
wilcox.test(rf_nsm,rf_sm,alternative="less")
```

```{r, warning=FALSE}
# SVC
svc_nsm = c(0.550,0.549,0.548,0.551,0.552,0.546,0.564,0.555,0.541,0.548)
svc_sm = c(0.541,0.546,0.545,0.542,0.549,0.545,0.545,0.553,0.541,0.546)
mean(svc_nsm)
sd(svc_nsm)
mean(svc_sm)
sd(svc_sm)

fligner.test(svc_nsm,svc_sm)
wilcox.test(svc_nsm,svc_sm, alternative="greater")
```

```{r, warning=FALSE}
# LDA
lda_nsm = c(0.598,0.600,0.598,0.587,0.599,0.595,0.599,0.595,0.595,0.593)
lda_sm = c(0.599,0.603,0.601,0.595,0.602,0.600,0.602,0.596,0.599,0.600)

mean(lda_nsm)
sd(lda_nsm)
mean(lda_sm)
sd(lda_sm)
fligner.test(lda_nsm,lda_sm)
wilcox.test(lda_nsm,lda_sm,alternative="less")
```

```{r, warning=FALSE}
# Gaussian Naive Bayes
nb_nsm = c(0.565,0.564,0.564,0.563,0.568,0.563,0.569,0.565,0.565,0.566)
nb_sm = c(0.568,0.564,0.565,0.563,0.570,0.565,0.571,0.565,0.566,0.566)
mean(nb_nsm)
sd(nb_nsm)
mean(nb_sm)
sd(nb_sm)
fligner.test(nb_nsm,nb_sm)
wilcox.test(nb_nsm,nb_sm, alternative="less")

```
```{r, warning=FALSE}
# Deep Neuronal Network (DNN)
dnn_nsm = c(0.621,0.637,0.625,0.613,0.610,0.607,0.620,0.622,0.612,0.636)
dnn_sm = c(0.710,0.682,0.677,0.698,0.709,0.704,0.705,0.672,0.662,0.611)

mean(dnn_nsm)
sd(dnn_nsm)
mean(dnn_sm)
sd(dnn_sm)
fligner.test(x=list(dnn_nsm,dnn_sm))
wilcox.test(dnn_nsm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# Decision Tree and DNN
wilcox.test(dt_sm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# Random Forest and DNN
wilcox.test(rf_sm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# SVC and DNN
wilcox.test(svc_sm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# LDA and DNN
wilcox.test(lda_sm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# Gaussian Naive Bayes and DNN
wilcox.test(nb_sm,dnn_sm, alternative="less")
```

```{r}

labels = factor(c(rep("DT",10),rep("RF",10),rep("SVM",10),rep("LDA",10),rep("GNB",10),rep("DNN",10)),levels=c("DT", "RF", "SVM", "LDA", "GNB", "DNN"))
scores = c(dt_sm,rf_sm,svc_sm,lda_sm,nb_sm,dnn_sm)

df  <- data.frame(
  labels  = labels,
  scores = scores
)

picture = ggplot(df, aes(x = labels, y = scores, fill=labels)) + 
  geom_boxplot()+
  stat_boxplot(geom="errorbar", width=0.3)+
  labs(x="Classifier", y = "Accuracy", color="")+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = palette1,labels = c("DT", "RF", "SVM", "LDA", "GNB", "DNN"))+
  scale_colour_manual(values = palette1) +
  guides(fill=guide_legend(title="Classifier"))+
  scale_y_continuous(limits=c(0.525,0.700))

```


```{r}
suppressPackageStartupMessages(library(dplyr))

df  <- data.frame(
  Classifier  = factor(c("DT","RF","SVM","LDA","GNB","DNN"),levels=c("DT", "RF", "SVM", "LDA", "GNB", "DNN")),
  Precision = c(0.669,0.693,0.560,0.614,0.627,0.712),
  Recall = c(0.592,0.619,0.541,0.598,0.568,0.679),
  F1score = c(0.574,0.614,0.525,0.598,0.544,0.682),
  Accuracy = c(0.592,0.619,0.541,0.598,0.568,0.679),
  AUC = c(0.853,0.888,0.830,0.859,0.833,0.934)
)

ggradar(df, values.radar = c(0.6,0.7,1),
        base.size = 10,
        font.radar = "times new roman",
        background.circle.colour = "white",
        axis.line.colour = "black",
        gridline.min.colour = "black",
        gridline.mid.colour = "black",
        gridline.max.colour = "black",
       
        group.line.width = 0.25,
        group.point.size = 2,
        group.colours = palette1)
```

