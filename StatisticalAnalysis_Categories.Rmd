---
title: "Obfuscated Privacy Malware Classifiers based on Memory Dumping Analysis - Privacy Malware Categories Classification"
author: "David Cevallos-Salas, Felipe Grijalva, José Estrada-Jiménez, Diego Benítez and Roberto Andrade"
output: html_notebook
---

```{r, warning=FALSE}
# Global configuration
knitr::opts_chunk$set(echo = TRUE)

# Libraries
library(ggplot2)
library(viridis)
library(kableExtra)
library(dplyr)
library(sur)
library(qqplotr)
library(DescTools)
library(phia)
library(emmeans)
library(multcompView)
library(multcomp, quietly = TRUE)

# Viridis palette
palette1 <- viridis(6, alpha= 1, begin = 0, end = 1, direction = 1, option="viridis")
palette2 <- viridis(6, alpha= 1, begin = 0, end = 1, direction = 1, option="viridis")
```

```{r, warning=FALSE}
# Decision Tree
dt_nsm = c(0.713,0.709,0.714,0.716,0.715,0.715,0.714,0.713,0.711,0.719)
dt_sm = c(0.713,0.709,0.715,0.708,0.715,0.712,0.714,0.712,0.711,0.719)
mean(dt_nsm)
sd(dt_nsm)
mean(dt_sm)
sd(dt_sm)
fligner.test(x=list(dt_nsm,dt_sm))
wilcox.test(dt_nsm,dt_sm, alternative="greater")
```

```{r, warning=FALSE}
# Random Forest
rf_nsm = c(0.755,0.752,0.744,0.746,0.761,0.756,0.761,0.750,0.742,0.760)
rf_sm = c(0.756,0.738,0.748,0.733,0.759,0.751,0.746,0.750,0.732,0.757)
mean(rf_nsm)
sd(rf_nsm)
mean(rf_sm)
sd(rf_sm)
fligner.test(x=list(rf_nsm,rf_sm))
wilcox.test(rf_nsm,rf_sm, alternative="greater")
```

```{r, warning=FALSE}
# SVC
svc_nsm = c(0.700,0.696,0.701,0.698,0.687,0.689,0.702,0.690,0.699,0.693)
svc_sm = c(0.698,0.699,0.691,0.698,0.695,0.701,0.695,0.678,0.679,0.698)
mean(svc_nsm)
sd(svc_nsm)
mean(svc_sm)
sd(svc_sm)
fligner.test(x=list(svc_nsm,svc_sm))
wilcox.test(svc_nsm,svc_sm, alternative="greater")

```

```{r, warning=FALSE}
# LDA
lda_nsm = c(0.724,0.721,0.720,0.725,0.721,0.721,0.719,0.715,0.729,0.725)
lda_sm = c(0.732,0.726,0.728,0.730,0.732,0.726,0.729,0.726,0.735,0.734)
mean(lda_nsm)
sd(lda_nsm)
mean(lda_sm)
sd(lda_sm)
fligner.test(x=list(lda_nsm,lda_sm))
wilcox.test(lda_nsm,lda_sm, alternative="less")
```
```{r, warning=FALSE}
# Gaussian Naive Bayes
nb_nsm = c(0.678,0.693,0.686,0.680,0.681,0.680,0.681,0.679,0.679,0.697)
nb_sm = c(0.679,0.697,0.686,0.681,0.682,0.682,0.683,0.679,0.679,0.705)
mean(nb_nsm)
sd(nb_nsm)
mean(nb_sm)
sd(nb_sm)
fligner.test(x=list(nb_nsm,nb_sm))
wilcox.test(nb_nsm,nb_sm, alternative="less")
```

```{r, warning=FALSE}
# Deep Neural Network (DNN)
dnn_nsm = c(0.763,0.732,0.758,0.751,0.753,0.728,0.761,0.773,0.756,0.762)
dnn_sm = c(0.772,0.766,0.760,0.769,0.782,0.775,0.779,0.778,0.763,0.743)

mean(dnn_nsm)
sd(dnn_nsm)
mean(dnn_sm)
sd(dnn_sm)
fligner.test(x=list(dnn_nsm,dnn_sm))
wilcox.test(dnn_nsm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# Decision Tree and DNN
wilcox.test(dt_sm,dnn_sm, alternative="less")
```
```{r, warning=FALSE}
# Random Forest and DNN
wilcox.test(rf_sm,dnn_sm, alternative="less")
```
```{r, warning=FALSE}
# SVC and DNN
wilcox.test(svc_sm,dnn_sm, alternative="less")
```

```{r, warning=FALSE}
# LDA and DNN
wilcox.test(lda_sm,dnn_sm, alternative="less")
```
```{r, warning=FALSE}
# Gaussian Naive Bayes and DNN
wilcox.test(nb_sm,dnn_sm, alternative="less")
```

```{r}

labels = factor(c(rep("DT",10),rep("RF",10),rep("SVM",10),rep("LDA",10),rep("GNB",10),rep("DNN",10)),levels=c("DT", "RF", "SVM", "LDA", "GNB", "DNN"))
scores = c(dt_sm,rf_sm,svc_sm,lda_sm,nb_sm,dnn_sm)

df  <- data.frame(
  labels  = labels,
  scores = scores
)

picture = ggplot(df, aes(x = labels, y = scores, fill=labels)) + 
  geom_boxplot()+
  stat_boxplot(geom="errorbar", width=0.3)+
  labs(x="Classifier", y = "Accuracy", color="")+
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = palette1,labels = c("DT", "RF", "SVM", "LDA", "GNB", "DNN"))+
  scale_colour_manual(values = palette1) +
  guides(fill=guide_legend(title="Classifier"))+
  scale_y_continuous(limits=c(0.675,0.7755))

```